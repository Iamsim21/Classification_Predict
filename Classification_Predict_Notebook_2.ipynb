{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data:\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/Iamsim21/Classification_Predict/main/train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/Iamsim21/Classification_Predict/main/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['message'] = train['message'].apply(word_tokenize)\n",
    "\n",
    "test['message'] = test['message'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['message'] = train['message'].astype(str)\n",
    "test['message'] = test['message'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['message'] = train['message'].apply(lambda x: RegexpTokenizer(\"[\\w+.]+\").tokenize(x))\n",
    "test['message'] = test['message'].apply(lambda x: RegexpTokenizer(\"[\\w+.]+\").tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [PolySciMajor, EPA, chief, does, n, t, think, ...\n",
       "1        [It, s, not, like, we, lack, evidence, of, ant...\n",
       "2        [RT, RawStory, Researchers, say, we, have, thr...\n",
       "3        [TodayinMaker, WIRED, 2016, was, a, pivotal, y...\n",
       "4        [RT, SoyNovioDeTodas, It, s, 2016, and, a, rac...\n",
       "                               ...                        \n",
       "15814    [RT, ezlusztig, They, took, down, the, materia...\n",
       "15815    [RT, washingtonpost, How, climate, change, cou...\n",
       "15816    [notiven, RT, nytimesworld, What, does, Trump,...\n",
       "15817    [RT, sara8smiles, Hey, liberals, the, climate,...\n",
       "15818    [RT, Chet_Cannon, ., kurteichenwald, s, climat...\n",
       "Name: message, Length: 15819, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_train = train['message']\n",
    "message_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [Europe, will, now, be, looking, to, China, to...\n",
       "1        [Combine, this, with, the, polling, of, staffe...\n",
       "2        [The, scary, unimpeachable, evidence, that, cl...\n",
       "3        [Karoli, morgfair, OsborneInk, dailykos, Putin...\n",
       "4        [RT, FakeWillMoore, Female, orgasms, cause, gl...\n",
       "                               ...                        \n",
       "10541    [RT, BrittanyBohrer, Brb, writing, a, poem, ab...\n",
       "10542    [2016, the, year, climate, change, came, home,...\n",
       "10543    [RT, loop_vanuatu, Pacific, countries, positiv...\n",
       "10544    [RT, xanria_00018, You, re, so, hot, you, must...\n",
       "10545    [RT, chloebalaoing, climate, change, is, a, gl...\n",
       "Name: message, Length: 10546, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_test = test['message']\n",
    "message_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtr = [' '.join(i) for i in message_train]\n",
    "mts = [' '.join(i) for i in message_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['message'] = pd.DataFrame(mtr, columns = ['message'])\n",
    "test['message'] = pd.DataFrame(mts, columns = ['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample data\n",
    "from sklearn.utils import resample \n",
    "\n",
    "yes = train[train['sentiment'] == 1]\n",
    "no = train[train['sentiment'] == -1]\n",
    "neutral = train[train['sentiment'] == 0]\n",
    "news = train[train['sentiment'] == 2]\n",
    "\n",
    "no_unsampled = resample(no, replace=True, n_samples=len(yes), random_state=27)\n",
    "ne_unsampled = resample(neutral, replace=True, n_samples=len(yes), random_state=27)\n",
    "nw_unsampled = resample(news, replace=True, n_samples=len(yes), random_state=27)\n",
    "\n",
    "unsampled = pd.concat([yes, no_unsampled, ne_unsampled, nw_unsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief does n t think carbon d...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It s not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>TodayinMaker WIRED 2016 was a pivotal year in ...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT SoyNovioDeTodas It s 2016 and a racist sexi...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Worth a read whether you do or do n t believe ...</td>\n",
       "      <td>425577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief does n t think carbon d...   625221\n",
       "1          1  It s not like we lack evidence of anthropogeni...   126103\n",
       "3          1  TodayinMaker WIRED 2016 was a pivotal year in ...   573736\n",
       "4          1  RT SoyNovioDeTodas It s 2016 and a racist sexi...   466954\n",
       "5          1  Worth a read whether you do or do n t believe ...   425577"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsampled.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply variables\n",
    "y = unsampled['sentiment']\n",
    "X = unsampled['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2),min_df=2, stop_words='english')\n",
    "X_vectorized = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train dataset into test and validation set: \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, shuffle=True, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1500, C=10)\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9601487780749538"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check f1-score:\n",
    "f1_score(y_test, logreg_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test set\n",
    "x_test = test['message']\n",
    "v_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make prediction on the test set and add a sentiment column to our orignal test dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction on the test set and add a sentiment column \n",
    "y_pred = logreg.predict(v_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['sentiment'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary unimpeachable evidence that climate ...</td>\n",
       "      <td>224985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Karoli morgfair OsborneInk dailykos Putin got ...</td>\n",
       "      <td>476263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT FakeWillMoore Female orgasms cause global w...</td>\n",
       "      <td>872928</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid  sentiment\n",
       "0  Europe will now be looking to China to make su...   169760          1\n",
       "1  Combine this with the polling of staffers re c...    35326          1\n",
       "2  The scary unimpeachable evidence that climate ...   224985          1\n",
       "3  Karoli morgfair OsborneInk dailykos Putin got ...   476263          1\n",
       "4  RT FakeWillMoore Female orgasms cause global w...   872928          1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an output csv submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['tweetid', 'sentiment']].to_csv('test_sub3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bit00c435921acd4ca686517f61614b63d4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
